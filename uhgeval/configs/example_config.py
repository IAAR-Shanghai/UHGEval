# ─── Models Accessed Through API ──────────────────────────────────────────────
# Note: If you want to use the models below, you need to apply for an API key for each model.

# Baichuan 53B
# Visit: https://platform.baichuan-ai.com/docs/api
Baichuan2_53B_url = ''
Baichuan2_53B_api_key = ''
Baichuan2_53B_secret_key = ''

# GPT series
# https://platform.openai.com/docs/guides/text-generation
GPT_api_key = ''


# ─── Models Accessed Through Remote Deployment ────────────────────────────────
# Note: Remote models are only for internal use.

Aquila_url = ''
Aquila_token = ''

Baichuan2_13B_url = ''
Baichuan2_13B_token = ''

ChatGLM2_url = ''
ChatGLM2_token = ''

GPT_transit_url = ''
GPT_transit_token = ''

InternLM_url = ''
InternLM_token = ''

Qwen_url = ''
Qwen_token = ''

Xinyu_7B_url = ''
Xinyu_7B_token = ''

Xinyu_70B_url = ''
Xinyu_70B_token = ''


# ─── Models Accessed Through Local Deployment ────────────────────────────────
# Note: Use vLLM to deploy models.
# Link: https://docs.vllm.ai/en/latest/getting_started/quickstart.html

BloomZ_3B_vllm_url = ''

InternLM2_1_8B_Chat_vllm_url = ''

LLaMA2_13B_Chat_vllm_url = ''

LLaMA2_70B_Chat_vllm_url = ''

LLaMA2_7B_Chat_vllm_url = ''

NewModel_vllm_url = ''

OPT_vllm_url = ''

PHI2_vllm_url = ''

Qwen1_5_4B_Chat_vllm_url = ''

# ─── Models Accessed Through Local Path ────────────────────────────────
# Note: Ensure model's files are in Huggingface format.

Aquila_local_path = ''

Baichuan2_13b_local_path = ''

ChatGLM3_local_path = ''

Qwen_local_path = ''

InternLM_local_path = ''
