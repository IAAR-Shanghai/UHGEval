# Three parts


# ─── General Configuration ────────────────────────────────────────────────────

enable_log_saving: true  # Whether to save logs

processes: 3             # Number of processes to use for parallel processing
num_blocks: 170          # Number of blocks to process
start_block: 0           # The block to start processing from
seed: 22                 # Seed for random number generation


# ─── Datasets To Be Evaluated On And The Evaluator It Uses ────────────────────

dataset:
- "xinhua.XinhuaHallucinations":
    path: "data/Xinhua/XinhuaHallucinations.json"
    evaluator:
    - "discriminative.DiscriminativeEvaluatorKeywordLevel"
    - "discriminative.DiscriminativeEvaluatorSentenceLevel"
    - "generative.GenerativeEvaluator"
    - "selective.SelectiveEvaluator"
- "truthfulqa.TruthfunQAGeneration":
    path: "data/TruthfulQA/TruthfulQA.csv"
    evaluator:
    - "TruthQAEvaluator.GenerativeEvaluatorTrutufulQA"
- "truthfulqa.TruthfunQAMC1":
    path: "data/TruthfulQA/mc_task.json"
    evaluator:
    - "TruthQAEvaluator.SelectiveEvaluatorMC1"
- "truthfulqa.TruthfunQAMC2":
    path: "data/TruthfulQA/mc_task.json"
    evaluator:
    - "TruthQAEvaluator.SelectiveEvaluatorMC2"
- "halueval.HaluEvalSummarization":
    path: "data/HaluEval/summarization_data.json"
    evaluator:
    - "HaluEvalEvaluator.HaluEvalSummarizationEvaluator"
- "halluqa.HalluQAMC":
    path: "data/HalluQA/HalluQA_mc.json"
    evaluator:
    - "HalluQAEvaluator.HalluQAMCEvaluator"


# ─── Models To Be Evaluated ───────────────────────────────────────────────────

llm:
    api:
    - GPT:
        model_name: gpt-3.5-turbo
        report: true
    local:
    - Baichuan2_13B_Chat:
        temperature: 0.8
        top_p: 0.6
    - ChatGLM3_6B_Chat:
        temperature: 0.8
        top_p: 0.6
    remote:
    - Qwen_14B_Chat:
        temperature: 0.8
    - Xinyu_7B_Chat:
        temperature: 0.8
